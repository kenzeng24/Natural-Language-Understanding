{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 2: Text Classification using LSTMs\n",
    "**Due: February 27, 9:30 AM**\n",
    "\n",
    "In this homework assignment, you will define and train an [LSTM model](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) for _sentiment analysis_, a text classification task that we learned about in the Week 2 lab and Week 3 lecture. In this task, the model will read a user-generated movie review from the website [IMDb](https://www.imdb.com/) and predict whether the review is a _positive review_ (class `1`) or a _negative review_ (class `0`). For instance, the model should classify `This movie is amazing!` as `1` (positive) and `This movie is terrible!` as `0` (negative).\n",
    "\n",
    "## Important: Read Before Starting\n",
    "\n",
    "In the following exercises, you will need to implement functions defined in the `tokenizer`, `model`, and `train_test` modules. **Please write all your code in the respective `.py` files for those modules.** You should not submit this notebook with your solutions, and we will not grade it if you do. Please be aware that code written in a Jupyter notebook may run differently when copied into Python modules.\n",
    "\n",
    "The outputs shown in this notebook are the outputs that you should get **when all problems have been completed correctly**. You may obtain different results if you attempt to run the code cells before you have completed the problem set, or if you have completed one or more problems incorrectly.\n",
    "\n",
    "To begin, please run the following `import` statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LC_ALL=en_US.UTF-8\n",
    "!export LANG=en_US.UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "from embeddings import Embeddings\n",
    "from model import LSTMSentimentClassifier\n",
    "from tokenizer import Tokenizer\n",
    "from train_test import evaluate, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = Embeddings.from_file(filename='data/glove_300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "vecs= torch.tensor(embeddings.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([vecs, vecs]).argmax(axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Inspect the Data (10 Points in Total)\n",
    "\n",
    "The official name of the dataset we are using is called the [Large Movie Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment/). More commonly, however, it is simply known as the _IMDb dataset_. It was originally created in 2011 by a group of graduate students at Stanford University supervised by Professors [Andrew Ng](https://www.andrewng.org/) and [Christopher Potts](https://web.stanford.edu/~cgpotts/). The IMDb dataset has since become one of the most commonly used sentiment analysis datasets in NLP research.\n",
    "\n",
    "### Problem 1a: Load and Inspect Examples (No Submission, 0 Points)\n",
    "\n",
    "In this assignment, we will work with the IMDb dataset using a Python interface provided by the ðŸ¤— Datasets library. This library stores a number of NLP datasets on a remote server, which you can download using the `load_dataset` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/kenzeng/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bbf3d102864c4baee7c1e81b5be7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "imdb = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IMDb dataset is split into three parts: `train`, `test`, and `unsupervised`. There is no validation set. (The `unsupervised` dataset contains movie reviews without labels.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will need a validation set for early stopping and hyperparameter tuning, we will take 20% of the training data and use that as the validation data, as we did during lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /Users/kenzeng/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-5bc6777a554460b1.arrow and /Users/kenzeng/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-68a38e526d30dc3c.arrow\n"
     ]
    }
   ],
   "source": [
    "split = imdb[\"train\"].train_test_split(.2, seed=3463)\n",
    "imdb[\"train\"] = split[\"train\"]\n",
    "imdb[\"val\"] = split[\"test\"]\n",
    "if \"unsupervised\" in imdb:\n",
    "    del imdb[\"unsupervised\"]  # Save memory by deleting the unlabeled examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of what the data look like, please inspect a few examples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Ever since I was eight years old I have been a big wrestling fan. It didn't matter what federation I watched. WWE,WCW,USWA. To me the action is all I watched it for.<br /><br />May 23rd 1999. That was my 19 birthday. I ordered Over the Edge and I was just expecting another pay per view. But this time. I was wrong. Instead that was the night one of the best wrestlers to come out of Canada a true human being fell to his death due to a stunt gone wrong. Not much you can do to change the situation. But what happened affter Owens death made me very mad.<br /><br />Rather then ending the pay per view and doing the right thing as human beings the WWE decided to protect what comes first and that was the money by keeping the pay per view going as if Owens death never happened.<br /><br />I gotta tell you. Vince Mchmaon has made some stupid decisions in his life but this was by far the stupidest decision he ever made.<br /><br />And this crap with saying Owen would have wanted the pay pew view to keep going. Give me a break. When someone dies on a pay pew view its comon sense to stop it. Thats like a police officer shooting a robber or a mugger with a run and then just leaving the man to die so he can go home and call it a day as if the mans life never mattered.<br /><br />But no matter what happens. Owen will be missed and thanks for the memories for all the times you gave us.\",\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb[\"train\"][1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1b: Benchmarks in NLP (Written, 5 Points)\n",
    "\n",
    "Many papers in the sentiment analysis literature use the IMDb dataset for training and testing. When a lot of papers use the same dataset, we refer to that dataset as a \"benchmark,\" and we often keep track of the best (\"state-of-the-art\") performance that has been achieved on each benchmark. For instance, the website [NLP-progress](https://nlpprogress.com/) lists state-of-the-art results for several NLP benchmarks, [including IMDb](http://nlpprogress.com/english/sentiment_analysis.html).\n",
    "\n",
    "Why would so many papers use the same dataset, instead of creating their own datasets? (Assume that it's not merely because of convenience.)\n",
    "\n",
    "- controls for confounding factors such as the quality of label collection + cleaning, underlying distributions \n",
    "- allows for fair comparison of different approaches \n",
    "\n",
    "### Problem 1c: Extra Credit (Written, 5 Points)\n",
    "\n",
    "Why do we use 20% of the training data as the validation dataset, instead of taking 20% from the testing data?\n",
    "\n",
    "**Hint:** Your answer should be related to your answer for Problem 1b.\n",
    "\n",
    "- \n",
    "\n",
    "\n",
    "### Problem 1d: Understanding the Dataset (Written, 5 Points)\n",
    "\n",
    "This screenshot shows [a typical movie review from the IMDb website](https://www.imdb.com/title/tt1630029/reviews/?ref_=tt_ql_urv).\n",
    "\n",
    "<img src=\"images/imdb-screenshot.png\" style=\"width:75%\" alt=\"A screenshot of a movie review from the IMDb website.\" />\n",
    "\n",
    "As you can see, IMDb reviews come with a text and a star rating out of 10; but nowhere does it say whether the review is \"positive\" or \"negative.\" According to [the original paper describing the IMDb dataset (Maas et al., 2011)](https://aclanthology.org/P11-1015/), how were the labels in the IMDb dataset assigned to each movie review?\n",
    "\n",
    "**Hint:** Sophie said something about this during lab on February 2, but she was wrong.\n",
    "\n",
    "## Problem 2: Tokenization (25 Points in Total)\n",
    "\n",
    "Now that you understand what the IMDb dataset looks like, the first step to building a sentiment analyzer is to build a _tokenizer_. Tokenization is the process of splitting up a string into pieces called _tokens_. For example, in this assignment the text `Hello world!` would be split up into the tokens `['Hello', 'world', '!']`. After tokenization, your tokenizer will replace each token with a unique numerical identifier, which the LSTM model will use to look up the word embedding for each token. Thus, the tokens `['Hello', 'world', '!']` will be replaced by the sequence of numbers `[3147, 207, 36]`.\n",
    "\n",
    "In this problem, you will implement the `Tokenizer` class in the `tokenizer` module.\n",
    "\n",
    "### Problem 2a: Inspect the GloVe Vocabulary (No Submission, 0 Points)\n",
    "\n",
    "The set of all possible unique tokens is called the _vocabulary_. Since we will use pre-trained GloVe embeddings in our sentiment analyzer, the vocabulary we use for tokenization simply consists of all the tokens that appear in the word embedding file.\n",
    "\n",
    "To help you load the GloVe embeddings, the starter code for this assignment comes with the solution code for Problem 1b of HW 1, where you implemented an `Embeddings` class that holds a set of word embeddings. Here we will use it to load 300-dimensional embeddings trained on 840 billion tokens from the Common Crawl corpus.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', '.', 'the', 'and', 'to', 'of', 'a', 'in', '\"', ':', 'is', 'for', 'I', ')', '(']\n"
     ]
    }
   ],
   "source": [
    "# Load the GloVe embeddings\n",
    "glove = Embeddings.from_file(\"data/glove_300d.txt\")\n",
    "\n",
    "# Inspect some of the words in the vocabulary\n",
    "print(glove.words[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the first 15 words in the GloVe vocabulary. What order do you think the words are in? Is the GloVe vocabulary case-sensitive?\n",
    "\n",
    "### Problem 2b: Extra Credit (Written, 5 Points)\n",
    "\n",
    "You might think that all a tokenizer needs to do is to separate out the words in a text. But remember from class that the concept of a \"word\" is difficult to define linguistically, so sometimes it might make sense for a word to be split up into multiple tokens. For example, observe below that the GloVe vocabulary contains common word pieces like `'s` and `n't`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'s\n",
      "n't\n"
     ]
    }
   ],
   "source": [
    "# Inspect the 20th and 40th words in the GloVe vocabulary\n",
    "print(glove.words[20]) \n",
    "print(glove.words[40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the linguistics term that refers to word pieces like `'s` or `n't`, as well as prefixes and suffixes like `pre-` or `-tion` and \"root\" words like `berry`? Why should these kinds of word pieces be treated as separate tokens?\n",
    "\n",
    "### Problem 2c: Understand Tokenizer Usage (No Submission, 0 Points)\n",
    "\n",
    "Your code for tokenization will belong to the `Tokenizer` class in the `tokenizer` module. Before you implement the tokenizer, take a look at the following usage examples to understand how the tokenizer should work.\n",
    "\n",
    "A `Tokenizer` object is instantiatiated from a vocabulary, represented as a list of strings where each string is a unique token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a tokenizer from the GloVe vocabulary\n",
    "tokenizer = Tokenizer(glove.words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `Tokenizer` is loaded, its vocabulary will contain all the unique tokens in the provided list of strings. It will also contain four additional tokens:\n",
    "* `[BOS]` (\"beginning of sequence\"), which marks the beginning of a text;\n",
    "* `[EOS]` (\"end of sequence\"), which marks the end of a text;\n",
    "* `[UNK]` (\"unknown\"), which represents any token not in the vocabulary; and\n",
    "* `[PAD]` (\"padding\"), a token that is appended to the end of certain texts to make sure that all the inputs in a mini-batch have the same length. (This is so that each mini-batch can be represented as a matrix.)\n",
    "\n",
    "Each vocabulary item is assigned a unique numerical identifier known as its _index_. The indices are assigned in the same order as in the vocabulary used to instantiate the `Tokenizer`. The four special tokens `[BOS]`, `[EOS]`, `[UNK]`, and `[PAD]` are assigned the last four indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 30004\n",
      ",\t0\n",
      ".\t1\n",
      "the\t2\n",
      "and\t3\n",
      "to\t4\n",
      "of\t5\n",
      "a\t6\n",
      "in\t7\n",
      "\"\t8\n",
      ":\t9\n",
      "is\t10\n",
      "for\t11\n",
      "I\t12\n",
      ")\t13\n",
      "(\t14\n",
      "[BOS]\t30000\n",
      "[EOS]\t30001\n",
      "[UNK]\t30002\n",
      "[PAD]\t30003\n"
     ]
    }
   ],
   "source": [
    "# Visualize some of the words and indices\n",
    "print(\"Vocabulary size:\", len(tokenizer))\n",
    "sample_words = glove.words[:15] + [\"[BOS]\", \"[EOS]\", \"[UNK]\", \"[PAD]\"]\n",
    "for w in sample_words:\n",
    "    print(w, tokenizer[w], sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Tokenizer` object can be called as a function. Its input is a `dict` containing the texts and labels for a mini-batch. It should tokenize all the texts in the mini-batch before adding `[BOS]`, `[EOS]`, and `[PAD]` tokens as appropriate. Its output should contain the mini-batch with the texts represented as a PyTorch `LongTensor`, where each token has been replaced by its index. It should also contain the length of each example (including `[BOS]` and `[EOS]`), also represented as a `LongTensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a raw input batch\n",
    "text1 = \"<em>The Shawshank Redemption</em> was a great movie.<br />I enjoyed \" \\\n",
    "        \"it a lot!\"\n",
    "text2 = \"This movie was terrible. I could barely watch it.\"\n",
    "batch = {\"text\": [text1, text2], \"label\": [1, 0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lengths': tensor([16, 13]),\n",
       " 'label': tensor([1, 0]),\n",
       " 'text': tensor([[30000,    22, 30002, 24052,    30,     6,   158,   603,     1,    12,\n",
       "           2203,    21,     6,   271,    36, 30001],\n",
       "         [30000,    76,   603,    30,  4534,     1,    12,   121,  5333,   712,\n",
       "             21,     1, 30001, 30003, 30003, 30003]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turning the raw input batch into a model input\n",
    "tokenizer(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2d: Implement the Tokenization Pipeline (Code, 10 Points)\n",
    "\n",
    "The first part of the tokenizer that you will implement is called the _tokenization pipeline_. This pipeline consists of three steps: _normalization_, _tokenization_, and _postprocessing_, in that order. After these three steps, an input text such as \n",
    "\n",
    "> <em>The Shawshank Redemption</em> was a great movie.<br />I enjoyed it a lot!\n",
    "\n",
    "will be transformed into a sequence of tokens such as\n",
    "\n",
    "`['[BOS]', 'The', '[UNK]', 'Redemption', 'was', 'a', 'great', 'movie', '.', 'I', 'enjoyed', 'it', 'a', 'lot', '!', '[EOS]']`\n",
    "\n",
    "\n",
    "**Normalization:** In the _normalization_ step, HTML tags are removed from the text. This step has already been implemented for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shawshank Redemption was a great movie. I enjoyed it a lot!\n"
     ]
    }
   ],
   "source": [
    "raw_text = batch[\"text\"][0]\n",
    "normalized_text = tokenizer.normalize(raw_text)\n",
    "print(normalized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenization:** In the _tokenization_ step, the text is divided into tokens. Some of the tokens may be out of vocabulary, but we will not worry about that in this step. You will use [NLTK's Penn Treebank Tokenizer](https://www.nltk.org/api/nltk.tokenize.treebank.html) for tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Shawshank', 'Redemption', 'was', 'a', 'great', 'movie', '.', 'I', 'enjoyed', 'it', 'a', 'lot', '!']\n"
     ]
    }
   ],
   "source": [
    "raw_tokens = tokenizer.tokenize(normalized_text)\n",
    "print(raw_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the NLTK tokenizer does not behave correctly when it is applied to more than one sentence. In the example below, `'great.'` is treated as a single token even though the period should be a separate token: `['great', '.']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Shawshank', 'Redemption', 'was', 'a', 'great', 'movie.', 'I', 'enjoyed', 'it', 'a', 'lot', '!']\n"
     ]
    }
   ],
   "source": [
    "nltk_tokenizer = TreebankWordTokenizer()\n",
    "print(nltk_tokenizer.tokenize(normalized_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain the correct behavior, you will need to perform [sentence segmentation](https://www.nltk.org/book/ch03.html) before the tokenization step. See [Section 3.8 of the NLTK book](https://www.nltk.org/book/ch03.html) for more details.\n",
    "\n",
    "**Postprocessing:** In the _postprocessing_ step, `'[BOS]'` is added to the beginning of each text, and `'[EOS]'` is added to the end of each text. Tokens not in the vocabulary are replaced by `'[UNK]'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[BOS]', 'The', '[UNK]', 'Redemption', 'was', 'a', 'great', 'movie', '.', 'I', 'enjoyed', 'it', 'a', 'lot', '!', '[EOS]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.postprocess(raw_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete this problem, you will need to implement the `tokenize` and `postprocess` methods of the `Tokenizer` class.\n",
    "\n",
    "### Problem 2e: Prepare Model Input (Code, 10 Points)\n",
    "\n",
    "With the tokenization pipeline complete, your next step is to implement the `Tokenizer.__call__` method, which defines the `Tokenizer`'s behavior when it is called as a function. The `Tokenizer`-as-function should apply the tokenization pipeline to each text in an input batch before converting it into a `LongTensor` with all the words replaced by their indices. All the texts in the batch should be combined into a single matrix (a 2-dimensional `LongTensor`), where the `[PAD]` token is repeatedly appended to shorter texts until all the texts are the same length. In addition, `__call__` should convert the labels to a 1-dimensional `LongTensor` and add a 1-dimensional `LongTensor` to the batch that indicates the number of tokens in each text, not including `'[PAD]'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lengths': tensor([16, 13]),\n",
       " 'label': tensor([1, 0]),\n",
       " 'text': tensor([[30000,    22, 30002, 24052,    30,     6,   158,   603,     1,    12,\n",
       "           2203,    21,     6,   271,    36, 30001],\n",
       "         [30000,    76,   603,    30,  4534,     1,    12,   121,  5333,   712,\n",
       "             21,     1, 30001, 30003, 30003, 30003]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = tokenizer(batch)\n",
    "batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 0: ['[BOS]', 'The', '[UNK]', 'Redemption', 'was', 'a', 'great', 'movie', '.', 'I', 'enjoyed', 'it', 'a', 'lot', '!', '[EOS]']\n",
      "Text 1: ['[BOS]', 'This', 'movie', 'was', 'terrible', '.', 'I', 'could', 'barely', 'watch', 'it', '.', '[EOS]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "# Visualize the tokens: notice that text2 has '[PAD]' at the end\n",
    "for i, text in enumerate(batch[\"text\"]):\n",
    "    print(\"Text {}:\".format(i), [tokenizer.words[t] for t in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Model Architecture Definition (25 Points in Total)\n",
    "\n",
    "In this problem, you will implement the `LSTMSentimentClassifier` class in the `model` module, which defines the architecture for your sentiment analysis model. The architecture for the model is illustrated in the following diagram.\n",
    "\n",
    "<img src=\"images/lstm.png\" style=\"width:75%\" alt=\"The architecture for the sentiment analysis classifier.\" />\n",
    "\n",
    "In this architecture, the word embedding for each word is fed into an LSTM encoder network, which computes a sequence of hidden state vectors. The last hidden state vector $\\boldsymbol{h}^{(n)}$ (with $n = 5$ in the diagram), computed when the LSTM reads $\\overrightarrow{\\text{[EOS]}}$, is used as an embedding for the text. A decoder networkâ€”here just a linear layerâ€”takes $\\boldsymbol{h}^{(n)}$ and predicts the label assigned to the text.\n",
    "\n",
    "Unlike with the SGNS architecture and the MLP architecture we saw during the Week 3 lab, the LSTM architecture in this assignment has no sigmoid activation function in the decoder. Instead, the decoder's linear layer produces a 2-dimensional output $\\hat{\\boldsymbol{y}} \\in \\mathbb{R}^2$:\n",
    "\n",
    "$$\\hat{\\boldsymbol{y}} = \\boldsymbol{W}\\boldsymbol{h}^{(n)} + \\boldsymbol{b}$$\n",
    "\n",
    "where $\\text{softmax}(\\hat{\\boldsymbol{y}})$ contains the probabilities assigned by the model to the two possible labels. The reason the softmax activation function is not shown in the diagram is because [PyTorch's `nn.CrossEntropyLoss` module](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) combines the softmax activation function and the cross-entropy loss function into a single module.\n",
    "\n",
    "### Problem 3a: Extra Credit (Written, 5 Points)\n",
    "\n",
    "The cross-entropy loss function for this assignment is given by:\n",
    "\n",
    "$$L(\\text{softmax}(\\hat{\\boldsymbol{y}}), y) = -\\ln(\\text{softmax}(\\hat{\\boldsymbol{y}})_{y + 1}) = \\begin{cases}\n",
    "-\\ln(e^{\\hat{y}_1}/(e^{\\hat{y}_1} + e^{\\hat{y}_2})), & y = 0 \\\\\n",
    "-\\ln(e^{\\hat{y}_2}/(e^{\\hat{y}_1} + e^{\\hat{y}_2})), & y = 1\n",
    "\\end{cases}$$\n",
    "\n",
    "where $y \\in \\lbrace 0, 1 \\rbrace$ is the true label of the input text. For each $i \\in \\lbrace 0, 1 \\rbrace$, compute \n",
    "\n",
    "$$\\frac{\\partial}{\\partial \\hat{y}_i} L(\\text{softmax}(\\hat{\\boldsymbol{y}}), y)$$\n",
    "\n",
    "by hand. Why do you think we are combining softmax and the cross-entropy loss function into a single module, as opposed to using a softmax module in the model architecture?\n",
    "\n",
    "### Problem 3b: Define Architecture Components (Code, 10 Points)\n",
    "\n",
    "Please implement the `__init__` method of the `LSTMSentimentClassifier`, paying close attention to the docstrings for the parameters. This method starts out with three incomplete lines of code, which are intended to define PyTorch modules that form part of the architecture. The only thing you need to do is to complete these lines of code by initializing the appropriate module. Please refer to [the `torch.nn` documentation](https://pytorch.org/docs/stable/nn.html) for guidance on the usage of these modules.\n",
    "\n",
    "The specific modules you should initialize are:\n",
    "* `nn.Embedding` ([see documentation](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html))\n",
    "* `nn.LSTM` ([see documentation](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html))\n",
    "* `nn.Linear` ([see documentation](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html))\n",
    "\n",
    "Please use the setting `batch_first=True` for the `nn.LSTM` module, and use the default values for all other keyword arguments. Please **do not** use the `nn.LSTMCell` module, which also implements an LSTM network.\n",
    "\n",
    "When this problem is finished, you should be able to instantiate an `LSTMSentimentClassifier` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with hidden size of 10\n",
    "from importlib import reload\n",
    "import model as modellib\n",
    "reload(modellib)\n",
    "model = modellib.LSTMSentimentClassifier(len(tokenizer), 300, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3c: Load Pre-Trained Embeddings (Code, 5 Points)\n",
    "\n",
    "Notice that in Problem 3b, you have defined the word embedding vectors used by the `LSTMSentimentClassifier` as parameters of the model. By default, parameters of PyTorch modules are initialized to random values. However, in this assignment you will initialize them to pre-trained GloVe embeddings.\n",
    "\n",
    "Please implement the `load_pretrained_embeddings` method, which sets the model's word embedding matrix to values defined by an `Embeddings` object. \n",
    "\n",
    "**Important:** The last 4 rows of the model's word embedding matrix should _not_ be initalized to pre-trained values, since they represent the `[BOS]`, `[EOS]`, `[UNK]`, and `[PAD]` tokens, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe Vectors:\n",
      "[[-0.082752  0.67204  -0.14987  ... -0.1918   -0.37846  -0.06589 ]\n",
      " [ 0.012001  0.20751  -0.12578  ...  0.13871  -0.36049  -0.035   ]\n",
      " [ 0.27204  -0.06203  -0.1884   ...  0.13015  -0.18317   0.1323  ]\n",
      " ...\n",
      " [ 0.44812   0.55796  -0.88695  ...  0.33111  -0.067436 -0.20892 ]\n",
      " [-0.60233  -0.30839  -0.24441  ...  0.2574   -0.18594  -0.076442]\n",
      " [-0.20681   0.20913   0.1064   ... -0.30741  -0.11888   0.032769]]\n",
      "\n",
      "Initialized Embeddings:\n",
      "tensor([[-0.0828,  0.6720, -0.1499,  ..., -0.1918, -0.3785, -0.0659],\n",
      "        [ 0.0120,  0.2075, -0.1258,  ...,  0.1387, -0.3605, -0.0350],\n",
      "        [ 0.2720, -0.0620, -0.1884,  ...,  0.1302, -0.1832,  0.1323],\n",
      "        ...,\n",
      "        [ 0.4481,  0.5580, -0.8870,  ...,  0.3311, -0.0674, -0.2089],\n",
      "        [-0.6023, -0.3084, -0.2444,  ...,  0.2574, -0.1859, -0.0764],\n",
      "        [-0.2068,  0.2091,  0.1064,  ..., -0.3074, -0.1189,  0.0328]])\n",
      "\n",
      "Random Embeddings for [BOS], [EOS], [UNK], and [PAD]:\n",
      "tensor([[-0.0581, -0.5485,  1.4825,  ...,  0.3752,  0.0261, -0.8417],\n",
      "        [-0.7503, -0.4076,  1.0271,  ..., -0.7563,  0.0102,  1.4335],\n",
      "        [-2.0077,  0.0658,  0.2703,  ..., -0.2379,  1.1861, -0.6335],\n",
      "        [ 0.4414,  0.3052, -0.7955,  ...,  0.3134,  0.7257,  0.0307]])\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model's word embeddings to pre-trained GloVe embeddings\n",
    "model.load_pretrained_embeddings(glove)\n",
    "\n",
    "# Visualize the pre-trained embeddings\n",
    "print(\"GloVe Vectors:\", glove.vectors, sep=\"\\n\", end=\"\\n\\n\")\n",
    "print(\"Initialized Embeddings:\", model.embeddings.weight[:-4], sep=\"\\n\", \n",
    "      end=\"\\n\\n\") \n",
    "\n",
    "# Your output here doesn't need to match the output shown\n",
    "print(\"Random Embeddings for [BOS], [EOS], [UNK], and [PAD]:\", \n",
    "      model.embeddings.weight[-4:], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3d: Define Forward Pass (Code, 15 Points)\n",
    "\n",
    "Please implement the `forward` method of the `LSTMSentimentClassifier`. When running the forward computation of the model, we do not call `forward` directly, but rather call the `LSTMSentimentClassifier` object as a function. The following snippet shows how this should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states, _ = model.lstm(model.embeddings(batch[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([398, 10])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[5,].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit scores:\n",
      "tensor([[0.0963, 0.4546],\n",
      "        [0.0611, 0.4811],\n",
      "        [0.0781, 0.3523],\n",
      "        [0.0925, 0.3837],\n",
      "        [0.0537, 0.4864],\n",
      "        [0.0843, 0.4594]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "Probabilities:\n",
      "tensor([[0.4114, 0.5886],\n",
      "        [0.3965, 0.6035],\n",
      "        [0.4319, 0.5681],\n",
      "        [0.4277, 0.5723],\n",
      "        [0.3935, 0.6065],\n",
      "        [0.4073, 0.5927]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Get the logit scores for each text \n",
    "logits = model(batch[\"text\"], batch[\"lengths\"])\n",
    "\n",
    "# Visualize the logit scores and probability scores\n",
    "print(\"Logit scores:\", logits, sep=\"\\n\", end=\"\\n\\n\")\n",
    "print(\"Probabilities:\", F.softmax(logits, dim=-1), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6]), torch.Size([6]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.argmax(axis=1).shape, batch['label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.argmax(axis=1) == batch['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output above, the first matrix (\"logit scores\") shows the output of the model, while the second matrix shows the softmax of the first matrix. The interpretation of the model's output is as follows:\n",
    "* the model predicts there is a 48.59% chance that `text1` has label `0`, and a 51.41% chance that `text1` has label `1`\n",
    "* the model predicts there is a 48.97% chance that `text2` has label `0`, and a 51.03% chance that `text2` has label `1`.\n",
    "\n",
    "Remember that this is a randomly initialized model that has not yet been trained, so these probabilities should not mean anything.\n",
    "\n",
    "## Problem 4: Training and Evaluation (40 Points in Total)\n",
    "\n",
    "You will now write code to train and test a sentiment classification model. For this problem, you will implement the `evaluate` and `train` functions in the `train_test` module.\n",
    "\n",
    "### Problem 4a: Dataset Preparation (No Submission, 0 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training and testing a model, you will first prepare the IMDb dataset by applying the data processing code you implemented in Problem 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = imdb[\"train\"].with_transform(tokenizer)\n",
    "val_data = imdb[\"val\"].with_transform(tokenizer)\n",
    "test_data = imdb[\"test\"].with_transform(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the code above, taking a slice from `train_data`, `val_data`, or `test_data` will result in a fully processed batch ready to be used as a model input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lengths': tensor([237, 302, 176]),\n",
       " 'label': tensor([1, 0, 0]),\n",
       " 'text': tensor([[30000,    12,    69,   601,   279,    21,   167,    56,     5,   167,\n",
       "              1,   569,     0,    83,    23,    85,  8891,   823,    28,   133,\n",
       "             28,  4511,    15,    23, 30002,    67,  2861,     2, 30002,     5,\n",
       "              2,   667,     1,    22,   448,   382,    10,   158,     3,   133,\n",
       "           6987,    54,    18,    38,  1328,   157,     4,   712,    27,  9536,\n",
       "              4,  1434,   700,    21,     1,    22,  1713,    23,  5436,     3,\n",
       "             59,    10,     2,   448,   382,     0,  1456,     4,    26,   568,\n",
       "            102,   372,   180,     4,   709, 20264,    34,   525,     0,    21,\n",
       "             20,     6,   667,   161,    43,    10,  3813,     7,     2,   283,\n",
       "              1,    22,  6368,    10,   158,     3,     2,  2354,     5, 30002,\n",
       "          10948,     3,   667, 30002,   827,     7,     6,   158,   667,    15,\n",
       "             10,  5790,   465,   639,    12,   178,   495,     7,  6368,     1,\n",
       "             62,    10,     6,   536,     3,   626,   667,     3,   105,  3058,\n",
       "           1640,     7,     6,   232,  4032,    59,    21,    20,  1016,  1539,\n",
       "             21,    17,     6,   112, 30002,     0,    32,  9616,     1,    22,\n",
       "           1289,  7034,    47,   962,    27,   667,     7,   105,   711,   611,\n",
       "              0,    42,    21,    69,    31,    84,    50, 12767,    68,    83,\n",
       "             87,    85,  1340, 13708,     4, 15040,    15,   105,  3408,  2421,\n",
       "              0,    12,  2203,    21,    50,     7,  1340,    19,   711, 21082,\n",
       "              1,   289,     2,   540,   105,   133,  1016,  1757,    17,  1121,\n",
       "             32, 30002,    68,    49,    31,    21,    36,   128,  3298,    68,\n",
       "             18,  2203,    27,   667,    18,   291,    89,    64,    54, 30002,\n",
       "            874,    63,  7140,     7,     6,  8348,    80, 30002,     0,    27,\n",
       "             10,    75,     6,   592,  6740,     1, 30001, 30003, 30003, 30003,\n",
       "          30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003,\n",
       "          30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003,\n",
       "          30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003,\n",
       "          30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003,\n",
       "          30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003,\n",
       "          30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003,\n",
       "          30003, 30003],\n",
       "         [30000,    12,    75,   218,   143,    29,    27,   195,  7077,     0,\n",
       "              3,    27,  8062, 18785, 14483,  1474, 30002,    10,     2, 30002,\n",
       "           2824,   667,    12,   178,   495,    27,   152,     0,  2419,   100,\n",
       "            153,  8062, 30002, 30002,    16,    67,    81,     2, 30002,     4,\n",
       "             25,   387,  1361,  1063,   184,    28,  5097,     1,    90,  8062,\n",
       "            479, 26050,     0, 30002,     6,  8062,   667,  3934, 30002,     5,\n",
       "           8062,  6541,  9088, 30002,  3632,     4,  4949,    16,  2500,   177,\n",
       "           6528, 30002,    11,     2,  1263,     0,     2,  1285,     3,     0,\n",
       "           2512,  2610,     0,     2, 30002,     3,  6494, 30002,     5,    58,\n",
       "          19048,  2057,     4, 30002,    60,  1119,    20,   959,    17,  5118,\n",
       "            302,    16,     4,  1142,   196, 18785,  7694, 13178,     1,   201,\n",
       "           8062,   171, 30002,  2281, 12366,    17,    58,  3022,     0,    67,\n",
       "            117,  8062,  2238, 30002,    58,  9231,     3,     0,     5,   366,\n",
       "              0,    58,  5116,     4,  2266,     2,  7546,  2057,     1,    14,\n",
       "             22,  2281, 12366,     0, 20194,     0,    43,   283,    25,   504,\n",
       "           1573,     7,     2,  8560,     0,    67,    10,  4119,    11,     6,\n",
       "           8062,  6541,     1, 30002,    13,    22, 30002,     0, 28042, 22467,\n",
       "             16,    74,    10,   568,     4,   228,     0,  1573, 14867,    15,\n",
       "             53,   541,  1907,  1539,  8062, 30002, 30002,    16,  7299,   578,\n",
       "             11,    60,   210,   203,    32,     2,   203,     5,    60,  6210,\n",
       "           3934,    28,    53,   759,    92,   782,     3,   782,   101,  5534,\n",
       "            156,     6,   633,     5,  1154,  6983, 30002,     1,    12,    47,\n",
       "             40,   113,   297,    53,   127,    40,    75,  1695,     6,  1315,\n",
       "             17,    60,   143,    15,   107,  8062, 12608,    73,     1, 30002,\n",
       "             22,  3934,    20, 19870,     0, 10473,    58, 12323, 30002,     0,\n",
       "            154,   211,    50,   100, 27619,     3,   759, 30002,    28,     2,\n",
       "           8066,  5434,  2714,    92,   101, 19231,     1,    93,   997,    49,\n",
       "            327,  1259,   483,   458,    17,    58,  1263,     4,   402,    92,\n",
       "             43, 29550,     1,  5267,  8062,  9457,   131,     0, 30002,    12,\n",
       "           1237, 25125,    11,     2,  9531,     4,  3297,     2,   667,  3934,\n",
       "              1, 30001],\n",
       "         [30000,  6964,  1354,     2,  9748,     0,     6,    77,     5, 30002,\n",
       "              3, 30002,     0,  6923,     3,     6,  1912,     5,    88,   789,\n",
       "           1801,  8713,     7,     6,  3139, 13072,  9913,   316, 30002,     1,\n",
       "            367,     2,    77,    12, 30002,  1240,  1161,   488,   104,  1435,\n",
       "             64, 30002,     0, 30002,  1095, 19811,     3, 30002, 30002,    14,\n",
       "            128,    74,    41,  1981,     2,  6494,  9358, 30002,    37,    13,\n",
       "            171,   305,    25,     2,  1022,   705,     0,    49,  1240,  3418,\n",
       "          30002,   789,  4719, 30002,    19,     6,   688,   184,  2062,   169,\n",
       "           6574,  5887,     3,    49,    31,  6638,   114,  6816,     1, 30002,\n",
       "           1240,  1105, 17171,    10,     6,  6142,     7, 14797,   176,    17,\n",
       "            126,   537,     5,  1435,    42,    18,  1240,  7378,   218,     4,\n",
       "            775,   830,   127,    49,   151, 30002,     7,     2,   106,   246,\n",
       "             37,   325,   366,    35,     1, 30002,  1240,  1105, 17171, 12509,\n",
       "             97,  1451,     5, 23249,    16,   348,    21,   154,   111,     2,\n",
       "            334,    15,    83,  1240,   269,    96,   324,  1309,   235,   169,\n",
       "           6574, 30002,     3,   331,  6574,  1029,    16,     3,  1135,  2698,\n",
       "             50,    64,     6,  3051,  9279,   603,   100,     6,   976,    61,\n",
       "              1,  1627,    21,    10,    37, 30001, 30003, 30003, 30003, 30003,\n",
       "          30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003,\n",
       "          30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003,\n",
       "          30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003,\n",
       "          30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003,\n",
       "          30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003,\n",
       "          30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003,\n",
       "          30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003,\n",
       "          30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003,\n",
       "          30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003,\n",
       "          30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003,\n",
       "          30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003,\n",
       "          30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003, 30003,\n",
       "          30003, 30003]])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a batch from the training data\n",
    "train_data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of testing your code, we will also create small versions of the IMDb dataset by taking 1% of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 200\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_data_small = train_data.shard(num_shards=100, index=0)\n",
    "val_data_small = train_data_small\n",
    "test_data_small = train_data_small\n",
    "print(train_data_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lengths': tensor([16, 13]),\n",
       " 'label': tensor([1, 0]),\n",
       " 'text': tensor([[30000,    22, 30002, 24052,    30,     6,   158,   603,     1,    12,\n",
       "           2203,    21,     6,   271,    36, 30001],\n",
       "         [30000,    76,   603,    30,  4534,     1,    12,   121,  5333,   712,\n",
       "             21,     1, 30001, 30003, 30003, 30003]])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in the snippet above that we are using the _same_ small data for training, validation, and testing. This is okay when it is solely being used to test your code, but not when we are actually training and evaluating a full model.\n",
    "\n",
    "### Problem 4b: Model Evaluation (Code, 10 Points)\n",
    "\n",
    "Please implement the `evaluate` function in `train_test`. This function should evaluate a model on a given testing dataset, returning its classification accuracy. In order to save memory, the evaluation should occur in mini-batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'train_test' from '/Users/kenzeng/Desktop/College/DSCI/NLU/hw2-main/train_test.py'>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import train_test\n",
    "reload(train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data_small\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(test_data), batch_size):\n",
    "        batch = test_data[i:i + batch_size]\n",
    "        output = model(batch['text'], batch['lengths'])\n",
    "        batch_correct = torch.sum(output.argmax(axis=1) == batch['label'])\n",
    "        correct += batch_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5350)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct * 1.0 / len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy before training: 0.535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_acc = train_test.evaluate(model, test_data_small)\n",
    "print(\"Test accuracy before training: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4c: Model Training (Code, 20 Points)\n",
    "\n",
    "Please implement the `train` function in `train_test`. This function should train a model using a given training set and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n",
      "Epoch 2 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n",
      "Epoch 3 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n",
      "Epoch 4 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n",
      "Epoch 5 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n",
      "Epoch 6 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n",
      "Epoch 7 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n",
      "Epoch 8 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n",
      "Epoch 9 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n",
      "Epoch 10 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n",
      "Epoch 11 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n",
      "Epoch 12 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n",
      "Epoch 13 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n",
      "Epoch 14 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n",
      "Epoch 15 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n",
      "Epoch 16 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:04<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n",
      "Epoch 17 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n",
      "Epoch 18 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n",
      "Epoch 19 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n",
      "Epoch 20 of 20\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:03<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy after training: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "train_test.train(model, train_data_small, val_data_small, max_epochs=20)\n",
    "\n",
    "# Evaluate the model\n",
    "test_acc = train_test.evaluate(model, test_data_small)\n",
    "print(\"Test accuracy after training: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your `train` function must fulfill the following criteria.\n",
    "* It must use the `nn.CrossEntropyLoss` module as the loss function. (This has already been instantiated for you; see [the documentation](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) for usage details.)\n",
    "* It must use `optim.Adam` as the optimization algorithm. (This has already been instantiated for you; see [the documentation](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) for usage details.)\n",
    "* It must save the version of the model with the best validation accuracy to a specified filename, and load this version model at the end of training. (See [the documentation on saving and loading models](https://pytorch.org/tutorials/beginner/saving_loading_models.html) for information on how to do this.)\n",
    "* The `train` function has no return value, but after it has finished running, the model passed to the function must contain the version of the model with the best validation performance.\n",
    "* An _epoch_ is when the `train` function loops through all the examples in the training data. Training should stop when a certain number of epochs (given by the `max_epochs` hyperparameter) have been completed.\n",
    "* The `train` function must use early stopping. That is, if a certain number of consecutive epochs (given by the `patience` hyperparameter) have been completed without attaining the highest validation accuracy so far, then training must end immediately even if the maximum number of epochs has not yet been reached.\n",
    "* The `train` function must allow for tuning the Adam learning rate and the batch size.\n",
    "\n",
    "### Problem 4d: Experiment (Written, 10 Points + 5 EC)\n",
    "\n",
    "To complete the assignment, you will perform an experiment that measures the impact of initializing the model's word embeddings to pre-trained GloVe embeddings. Using the default hyperparameter settings (or the settings found using hyperparameter tuning, if you choose to do the optional extra credit problem below), please train and test two LSTM sentiment classifiers with an embedding size of 300 and hidden size of 10: one with the embedding matrix initialized to pre-trained GloVe embeddings, and one with the embedding matrix initialized randomly. Report the final test accuracies attained for both models, and comment (1 to 2 sentences) on any differences you observe between the two models.\n",
    "\n",
    "**Warning:** The code can take a long time to run.\n",
    "\n",
    "**Optional:** Up to 5 extra credit points may be award for hyperparameter tuning. Before completing this problem, please report the highest validation accuracy attained for at least 3 combinations of values for the following hyperparameters: `batch_size`, `max_epochs`, `patience`, and `lr` (the Adam learning rate). At least one of the 3 configurations must be the default settings. Then, complete this problem using the hyperparameter values with the best validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
